{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.python.ops.numpy_ops import np_config\n",
    "np_config.enable_numpy_behavior()\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train and test dataset\n",
    "def concatImages(pt1,pt2):\n",
    "  e1 = cv2.imread(pt1,cv2.IMREAD_GRAYSCALE)\n",
    "  e2 = cv2.imread(pt2,cv2.IMREAD_GRAYSCALE)\n",
    "  return np.concatenate((e1,e2),axis=1)\n",
    "\n",
    "# scale pixels\n",
    "def prep_pixels(tensor_arr):\n",
    "  # convert from integers to floats\n",
    "  train_norm = tensor_arr.astype('float32')\n",
    "  # normalize to range 0-1\n",
    "  train_norm = train_norm / 255.0\n",
    "  # return normalized images\n",
    "  return train_norm\n",
    "\n",
    "def loadIntraClass(db_root):\n",
    "  trainX = []\n",
    "  trainY = []\n",
    "  dirs = os.listdir(db_root)\n",
    "  for dir in dirs:\n",
    "    files = os.listdir(db_root+dir)\n",
    "    for k1 in range(len(files)-1):\n",
    "      for k2 in range(k1+1, len(files)):\n",
    "        trainX.append(concatImages(f'{db_root}{dir}/{files[k1]}', f'{db_root}{dir}/{files[k2]}'))\n",
    "        trainY.append([1,0])\n",
    "  return trainX, trainY\n",
    "\n",
    "def loadInterClass(db_root):\n",
    "  random.seed(100)\n",
    "  trainX = []\n",
    "  trainY = []\n",
    "  dirs = os.listdir(db_root)\n",
    "  for dir1 in range(len(dirs)-1):\n",
    "    files1 = os.listdir(db_root+dirs[dir1])\n",
    "    for dir2 in range(dir1, len(dirs)):\n",
    "      files2 = os.listdir(db_root+dirs[dir2])\n",
    "      n1 = len(files1)\n",
    "      n2 = len(files2)\n",
    "      if(n1*n2>77):\n",
    "        #generate 77 non matches\n",
    "        samples = []\n",
    "        while(len(samples)<77):\n",
    "          k1 = random.randint(0,n1-1)\n",
    "          k2 = random.randint(0,n2-1)\n",
    "          if((k1,k2) not in samples):\n",
    "            samples.append((k1,k2))\n",
    "        for (k1,k2) in samples:\n",
    "          trainX.append(concatImages(f'{db_root}{dirs[dir1]}/{files1[k1]}', f'{db_root}{dirs[dir2]}/{files2[k2]}'))\n",
    "          trainY.append([0,1])\n",
    "      else:\n",
    "        for k1 in files1:\n",
    "          for k2 in files2:\n",
    "            trainX.append(concatImages(f'{db_root}{dirs[dir1]}/{k1}', f'{db_root}{dirs[dir2]}/{k2}'))\n",
    "            trainY.append([0,1])\n",
    "  return trainX, trainY\n",
    "\n",
    "def load_tensors(db_root):\n",
    "  X,Y = loadIntraClass(db_root)\n",
    "  X1,Y1 = loadInterClass(db_root)\n",
    "  X.extend(X1)\n",
    "  Y.extend(Y1)\n",
    "  X = tf.convert_to_tensor(X)\n",
    "  X = prep_pixels(X)\n",
    "  Y = tf.convert_to_tensor(Y)\n",
    "  X.reshape((X.shape[0], 160, 280, 1))\n",
    "  print(X.shape)\n",
    "  return X,Y\n",
    "\n",
    "def load_dataset(db_root):\n",
    "  # load dataset\n",
    "  trainX, trainY = load_tensors(db_root)\n",
    "  testX, testY = load_tensors('features/test/m1/')\n",
    "  return trainX, trainY, testX, testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12856, 160, 280)\n",
      "(5610, 160, 280)\n"
     ]
    }
   ],
   "source": [
    "trainX, trainY, testX, testY = load_dataset('features/m1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12856, 2) (5610, 2)\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# define cnn model\n",
    "def define_model():\n",
    "  model = Sequential()\n",
    "  model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', input_shape=(160, 280, 1)))\n",
    "  model.add(MaxPooling2D((3, 3)))\n",
    "  model.add(Flatten())\n",
    "  model.add(Dense(200, activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))\n",
    "  model.add(Dense(2, activation='softmax'))\n",
    "  # compile model\n",
    "  opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "  model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# run the test harness for evaluating a model\n",
    "def run_test_harness(trainX, trainY, testX, testY):\n",
    "  # load dataset\n",
    "  \n",
    "  # prepare pixel data\n",
    "  trainX = prep_pixels(trainX)\n",
    "  \n",
    "  # evaluate model\n",
    "  model = define_model()\n",
    "  #trainX, testX, trainY, testY = train_test_split(trainX, trainY, test_size=0.2, random_state=0)\n",
    "  model.fit(trainX, trainY, epochs=5, batch_size=256)\n",
    "  \n",
    "  print(trainX.shape, testX.shape)\n",
    "  # learning curves\n",
    "  #summarize_diagnostics(histories)\n",
    "  # summarize estimated performance\n",
    "  model.save_weights('./tf_models/matcher2.pth')\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "51/51 [==============================] - 141s 3s/step - loss: 0.6040 - accuracy: 0.7196\n",
      "Epoch 2/5\n",
      "51/51 [==============================] - 121s 2s/step - loss: 0.3026 - accuracy: 0.8778\n",
      "Epoch 3/5\n",
      "51/51 [==============================] - 124s 2s/step - loss: 0.2813 - accuracy: 0.8846\n",
      "Epoch 4/5\n",
      "51/51 [==============================] - 128s 3s/step - loss: 0.2025 - accuracy: 0.9253\n",
      "Epoch 5/5\n",
      "51/51 [==============================] - 128s 3s/step - loss: 0.1787 - accuracy: 0.9345\n",
      "(12856, 160, 280) (5610, 160, 280)\n"
     ]
    }
   ],
   "source": [
    "model = run_test_harness(trainX, trainY, testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176/176 [==============================] - 19s 105ms/step - loss: 0.6470 - accuracy: 0.7635\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6469579339027405, 0.7634581327438354]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x27880005210>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = define_model()\n",
    "model.load_weights('./tf_models/matcher2.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b153a99c3a4485f0e00ad4da8a083284092373fd5e464cfa1a038656a443ffa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
